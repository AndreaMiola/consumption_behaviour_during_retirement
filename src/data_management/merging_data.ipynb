{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mergeid      co002e      co003e\n",
      "0      AT-000327-01         NaN         NaN\n",
      "1      AT-000327-02         500           0\n",
      "2      AT-001816-01         250         250\n",
      "3      AT-001816-02         NaN         NaN\n",
      "4      AT-002132-01  Don't know  Don't know\n",
      "...             ...         ...         ...\n",
      "30419  SE-998807-02         NaN         NaN\n",
      "30420  SE-998962-01  Don't know           0\n",
      "30421  SE-999112-01  Don't know  Don't know\n",
      "30422  SE-999112-02         NaN         NaN\n",
      "30423  SE-999718-01     136.997     5.47987\n",
      "\n",
      "[30424 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "#WAVE_1_2004\n",
    "\n",
    "# Employment and pension status\n",
    "ep1_df = pd.read_stata('../original_data/WAVE_1_2004/sharew1_rel7-0-0_ep.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "ep1_df = ep1_df[['mergeid', 'ep005_', 'ep106_1']]\n",
    "\n",
    "# Restriction: each respondent have to be working at the first wave. \n",
    "ep1_df = ep1_df[ep1_df['ep005_'] == 'Employed or self-employed (including working for family business)']\n",
    "\n",
    "# Restriction: keep only respondent who answer to the question about expected retirment \n",
    "ep1_df = ep1_df[ep1_df.ep106_1.notnull()]\n",
    "\n",
    "\n",
    "# Extract a column that represents the employed invidual worked on wave 1.\n",
    "key = ep1_df['mergeid']\n",
    "\n",
    "\n",
    "# Add education level data as Standard Classification of Education (ISCED)\n",
    "edu1_df = pd.read_stata('../original_data/WAVE_1_2004/sharew1_rel7-0-0_gv_isced.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest \n",
    "edu1_df = edu1_df[['mergeid', 'isced1997y_r']]\n",
    "\n",
    "# Rename the column isced1997y_r as Year od Education\n",
    "edu1_df = edu1_df.rename(columns={\"isced1997y_r\" : \"educ_year\"})\n",
    "\n",
    "\n",
    "# Consumption data\n",
    "\n",
    "co1_df = pd.read_stata('../original_data/WAVE_1_2004/sharew1_rel7-0-0_co.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "co1_df = co1_df[['mergeid', 'co002e', 'co003e']]\n",
    "\n",
    "# Replace strings values with NaN\n",
    "#strings = [\"Don't know\", \"Refusal\", \"Other\", \"None\"]\n",
    "#co1_df.replace(strings, np.nan, inplace=True)\n",
    "\n",
    "#co1_df = co1_df[co1_df.co002e.notnull()]\n",
    "\n",
    "print(co1_df)\n",
    "\n",
    "# Coverscreen on individual level\n",
    "\n",
    "cv1_df = pd.read_stata('../original_data/WAVE_1_2004/sharew1_rel7-0-0_cv_r.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "cv1_df = cv1_df[[\"mergeid\", \"country\", \"hhsize\", \"gender\", \"yrbirth\", \"int_year\", \"partnerinhh\"]]\n",
    "\n",
    "\n",
    "# Merge dataframes of wave_1\n",
    "\n",
    "# Define a list of first wave dataframe\n",
    "wave1_df = [ep1_df, co1_df, cv1_df, edu1_df]\n",
    "\n",
    "# Set mergeid as index\n",
    "for x in wave1_df:\n",
    "    x.set_index(['mergeid'], inplace=True)\n",
    "\n",
    "# Merge the data \n",
    "wave1_df = reduce(lambda left,right: pd.merge(left,right,on='mergeid'), wave1_df)\n",
    "\n",
    "\n",
    "# Add column 'time' to indentify the wave\n",
    "wave1_df.insert(0, 'time', '2004')\n",
    "\n",
    "# Add column age at the dataframe\n",
    "#wave1_df['time'] = wave1_df['time'].astype(int)\n",
    "#wave1_df['year_birth'] = wave1_df['year_birth'].astype(int)\n",
    "#wave1_df['Age'] = wave1_df['time'] - wave1_df['year_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from WAVE_2_2006\n",
    "\n",
    "# Employment and pension status\n",
    "\n",
    "ep2_df = pd.read_stata('../original_data/WAVE_2_2006/sharew2_rel7-0-0_ep.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "ep2_df = ep2_df[['mergeid', 'ep005_']]\n",
    "\n",
    "# Consumption data\n",
    "\n",
    "co2_df = pd.read_stata('../original_data/WAVE_2_2006/sharew2_rel7-0-0_co.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "co2_df = co2_df[['mergeid', 'co002e', 'co003e']]\n",
    "\n",
    "# Coverscreen on individual level\n",
    "\n",
    "cv2_df = pd.read_stata('../original_data/WAVE_2_2006/sharew2_rel7-0-0_cv_r.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "cv2_df = cv2_df[[\"mergeid\", \"country\", \"hhsize\", \"gender\", \"yrbirth\", \"int_year\", \"partnerinhh\"]]\n",
    "\n",
    "\n",
    "# Merge dataframes of wave_2\n",
    "\n",
    "# Define a list of first wave dataframe\n",
    "wave2_df = [ep2_df, co2_df, cv2_df]\n",
    "\n",
    "# Set mergeid as index\n",
    "for x in wave2_df:\n",
    "    x.set_index(['mergeid'], inplace=True)\n",
    "\n",
    "# Merge the data \n",
    "wave2_df = reduce(lambda left,right: pd.merge(left,right,on='mergeid'), wave2_df)\n",
    "\n",
    "# Add column 'time' to indentify the wave\n",
    "wave2_df.insert(0, 'time', '2006')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from WAVE_4_2011\n",
    "\n",
    "# Employment and pension status\n",
    "ep4_df = pd.read_stata('../original_data/WAVE_4_2011/sharew4_rel7-0-0_ep.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "ep4_df = ep4_df[['mergeid', 'ep005_']]\n",
    "\n",
    "# Consumption data\n",
    "\n",
    "co4_df = pd.read_stata('../original_data/WAVE_4_2011/sharew4_rel7-0-0_co.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "co4_df = co4_df[['mergeid', 'co002e', 'co003e']]\n",
    "\n",
    "# Coverscreen on individual level\n",
    "\n",
    "cv4_df = pd.read_stata('../original_data/WAVE_4_2011/sharew4_rel7-0-0_cv_r.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "cv4_df = cv4_df[[\"mergeid\", \"country\", \"hhsize\", \"gender\", \"yrbirth\", \"int_year\", \"partnerinhh\"]]\n",
    "\n",
    "# Merge dataframes of wave_4\n",
    "\n",
    "# Define a list of first wave dataframe\n",
    "wave4_df = [ep4_df, co4_df, cv4_df]\n",
    "\n",
    "# Set mergeid as index\n",
    "for x in wave4_df:\n",
    "    x.set_index(['mergeid'], inplace=True)\n",
    "\n",
    "# Merge the data \n",
    "wave4_df = reduce(lambda left,right: pd.merge(left,right,on='mergeid'), wave4_df)\n",
    "\n",
    "# Add column 'time' to indentify the wave\n",
    "wave4_df.insert(0, 'time', '2011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from WAVE_5_2013\n",
    "\n",
    "# Employment and pension status\n",
    "ep5_df = pd.read_stata('../original_data/WAVE_5_2013/sharew5_rel7-0-0_ep.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "ep5_df = ep5_df[['mergeid', 'ep005_']]\n",
    "\n",
    "# Consumption data\n",
    "\n",
    "co5_df = pd.read_stata('../original_data/WAVE_5_2013/sharew5_rel7-0-0_co.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "co5_df = co5_df[['mergeid', 'co002e', 'co003e']]\n",
    "\n",
    "# Coverscreen on individual level\n",
    "\n",
    "cv5_df = pd.read_stata('../original_data/WAVE_5_2013/sharew5_rel7-0-0_cv_r.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "cv5_df = cv5_df[[\"mergeid\", \"country\", \"hhsize\", \"gender\", \"yrbirth\", \"int_year\", \"partnerinhh\"]]\n",
    "\n",
    "\n",
    "# Merge dataframes of wave_5\n",
    "\n",
    "# Define a list of first wave dataframe\n",
    "wave5_df = [ep5_df, co5_df, cv5_df]\n",
    "\n",
    "# Set mergeid as index\n",
    "for x in wave5_df:\n",
    "    x.set_index(['mergeid'], inplace=True)\n",
    "\n",
    "# Merge the data \n",
    "wave5_df = reduce(lambda left,right: pd.merge(left,right,on='mergeid'), wave5_df)\n",
    "\n",
    "# Add column 'time' to indentify the wave\n",
    "wave5_df.insert(0, 'time', '2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from WAVE_6_2015\n",
    "\n",
    "# Employment and pension status\n",
    "\n",
    "ep6_df = pd.read_stata('../original_data/WAVE_6_2015/sharew6_rel7-0-0_ep.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "ep6_df = ep6_df[['mergeid', 'ep005_']]\n",
    "\n",
    "\n",
    "# Consumption data\n",
    "\n",
    "co6_df = pd.read_stata('../original_data/WAVE_6_2015/sharew6_rel7-0-0_co.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "co6_df = co6_df[['mergeid', 'co002e', 'co003e']]\n",
    "\n",
    "# Coverscreen on individual level\n",
    "\n",
    "cv6_df = pd.read_stata('../original_data/WAVE_6_2015/sharew6_rel7-0-0_cv_r.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "cv6_df = cv6_df[[\"mergeid\", \"country\", \"hhsize\", \"gender\", \"yrbirth\", \"int_year\", \"partnerinhh\"]]\n",
    "\n",
    "\n",
    "# Merge dataframes of wave_6\n",
    "\n",
    "# Define a list of first wave dataframe\n",
    "wave6_df = [ep6_df, co6_df, cv6_df]\n",
    "\n",
    "# Set mergeid as index\n",
    "for x in wave6_df:\n",
    "    x.set_index(['mergeid'], inplace=True)\n",
    "\n",
    "# Merge the data \n",
    "wave6_df = reduce(lambda left,right: pd.merge(left,right,on='mergeid'), wave6_df)\n",
    "\n",
    "# Add column 'time' to indentify the wave\n",
    "wave6_df.insert(0, 'time', '2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from WAVE_7_2017\n",
    "\n",
    "# Employment and pension status\n",
    "\n",
    "ep7_df = pd.read_stata('../original_data/WAVE_7_2017/sharew7_rel7-0-0_ep.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "ep7_df = ep7_df[['mergeid', 'ep005_']]\n",
    "\n",
    "\n",
    "# Consumption data\n",
    "\n",
    "co7_df = pd.read_stata('../original_data/WAVE_7_2017/sharew7_rel7-0-0_co.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "co7_df = co7_df[['mergeid', 'co002e', 'co003e']]\n",
    "\n",
    "# Coverscreen on individual level\n",
    "\n",
    "cv7_df = pd.read_stata('../original_data/WAVE_7_2017/sharew7_rel7-0-0_cv_r.dta')\n",
    "\n",
    "# Selecte from dataframe the columns of interest\n",
    "cv7_df = cv7_df[[\"mergeid\", \"country\", \"hhsize\", \"gender\", \"yrbirth\", \"int_year\", \"partnerinhh\"]]\n",
    "\n",
    "\n",
    "# Merge dataframes of wave_7\n",
    "\n",
    "# Define a list of first wave dataframe\n",
    "wave7_df = [ep7_df, co7_df, cv7_df]\n",
    "\n",
    "# Set mergeid as index\n",
    "for x in wave7_df:\n",
    "    x.set_index(['mergeid'], inplace=True)\n",
    "\n",
    "# Merge the data \n",
    "wave7_df = reduce(lambda left,right: pd.merge(left,right,on='mergeid'), wave7_df)\n",
    "\n",
    "# Add column 'time' to indentify the wave\n",
    "wave7_df.insert(0, 'time', '2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\.conda\\envs\\consumption_behaviuor_during_retirment\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "share = wave1_df.append([wave2_df, wave4_df, wave5_df, wave6_df, wave7_df])\n",
    "share = share.sort_values(['mergeid', 'time'])\n",
    "\n",
    "share_merged = pd.merge(share, key, on='mergeid').set_index([\"mergeid\", \"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data = share_merged.to_csv(r'../original_data/share_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-consumption_behaviuor_during_retirment] *",
   "language": "python",
   "name": "conda-env-.conda-consumption_behaviuor_during_retirment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
